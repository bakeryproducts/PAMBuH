{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'output/2021_Feb_10_19_55_56_PAMBUH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "# sys.path.append(p  + 'src')\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import albumentations as albu\n",
    "from tqdm.notebook import tqdm\n",
    "import _data\n",
    "import augs\n",
    "import callbacks\n",
    "import sampler\n",
    "import model as nn_model\n",
    "from config import cfg, cfg_init\n",
    "from postprocessing import read_and_process_img, postprocess_test_folder, _plot_img\n",
    "from sampler import get_basics_rasterio\n",
    "\n",
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = data.build_datasets(cfg)\n",
    "# dls = data.build_dataloaders(cfg, datasets, pin=True, drop_last=False)\n",
    "# tdl = dls['TRAIN']\n",
    "# xb,yb = next(iter(tdl))\n",
    "# xb.shape, yb.shape\n",
    "\n",
    "# s = sampler.tif_block_read('./input/hm/test/b2dc8411c.tiff')\n",
    "# _,_,img = next(iter(s))\n",
    "# img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_tiff_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_path(p):\n",
    "    name = str(p.name)\n",
    "    epoch = name.split('_')[0]\n",
    "    return int(epoch[1:])\n",
    "\n",
    "def get_last_model(src):\n",
    "    # assumes that model name is of type e500_blabla.pth, sorted by epoch #500\n",
    "    models = list(Path(src).glob('*.pth'))\n",
    "    res = []\n",
    "    for i, m in enumerate(models):\n",
    "        epoch = parse_model_path(m)\n",
    "        #print(m, epoch)\n",
    "        \n",
    "        res.append([i,epoch])\n",
    "    idx = sorted(res, key=lambda x: -x[1])[0][0]\n",
    "    return models[idx]\n",
    "\n",
    "def rescale(batch_img, scale): return F.interpolate(batch_img, scale_factor=(scale, scale))\n",
    "\n",
    "def preprocess_image(cfg, img):\n",
    "    train_trans = augs.get_aug('light', cfg.TRANSFORMERS)\n",
    "    transform = train_trans.transforms.transforms[-1]\n",
    "    #print(transform)\n",
    "    #transform = albu.Compose([albu.Normalize(mean=cfg.TRANSFORMERS.MEAN, std=cfg.TRANSFORMERS.STD)])\n",
    "    ch, H,W, dtype = *img.shape, img.dtype\n",
    "    assert ch==3\n",
    "    assert dtype==np.uint8, dtype\n",
    "    img = img.transpose(1,2,0)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (W//2, H//2))\n",
    "    return transform(image=img)['image']\n",
    "    \n",
    "def _infer_func(imgs, cfg, model):\n",
    "    batch = []\n",
    "    for img in imgs:\n",
    "        batch.append(preprocess_image(cfg, img))\n",
    "    \n",
    "    batch = torch.stack(batch,axis=0)\n",
    "    #print(batch.shape, batch.dtype)\n",
    "    with torch.no_grad():\n",
    "        res = torch.sigmoid(model(batch))\n",
    "    res = rescale(res, 2)\n",
    "    return res\n",
    "\n",
    "def get_infer_func(p):\n",
    "    cfg_init(p + 'cfg.yaml')\n",
    "    cfg['PARALLEL']['DDP'] = False\n",
    "    cfg['DATA']['TRAIN']['PRELOAD'] = False\n",
    "        \n",
    "    model_path = get_last_model(p + 'models')\n",
    "    m = nn_model.load_model(cfg, str(model_path))\n",
    "    \n",
    "    return partial(_infer_func, cfg=cfg, model=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = get_infer_func(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage/HuBMAP/test/b9a3865fc.tiff\n"
     ]
    }
   ],
   "source": [
    "src_folder = '/mnt/storage/HuBMAP/test/'\n",
    "img_name = next(Path(src_folder).glob('*.tiff'))\n",
    "print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31295 40429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08b56850f8941688182bc9f69732a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rows:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de5ef31ea60446497382e2b86ad028e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "columns:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-088aa15f5a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_process_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-088aa15f5a3f>\u001b[0m in \u001b[0;36mread_and_process_img\u001b[0;34m(path, do_infer, block_size, crop_size, cuda)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
     ]
    }
   ],
   "source": [
    "def read_and_process_img(path : str, do_infer, block_size : int = 512, crop_size : int = 500, cuda : bool = True) -> np.ndarray:\n",
    "    assert block_size >= crop_size, (block_size, crop_size)\n",
    "    cuda = cuda and torch.cuda.is_available()\n",
    "    fd, (h, w), channel = get_basics_rasterio(path)\n",
    "    print(h, w)\n",
    "    pad = (block_size - crop_size)//2\n",
    "    rows = []\n",
    "    -pad, h\n",
    "    for y in tqdm(range(25000, 27000, crop_size), desc='rows'):\n",
    "        row, zeros_idx = [], []\n",
    "        for i, x in enumerate(tqdm(range(-pad, w, crop_size), desc='columns')):\n",
    "            pad_x = (pad if x < 0 else 0, x + block_size - w if x + block_size > w else 0)\n",
    "            pad_y = (pad if y < 0 else 0, y + block_size - h if y + block_size > h else 0)\n",
    "            pad_chw = ((0, 0), pad_y, pad_x)\n",
    "            block = get_tiff_block(fd, x, y, block_size)\n",
    "            pad_block = np.pad(block, pad_chw, 'constant', constant_values=0)\n",
    "            if pad_block.max() > 0:\n",
    "                row.append(pad_block)\n",
    "            else:\n",
    "                zeros_idx.append(i)\n",
    "        if row:\n",
    "            nozero_masks = do_infer(row)[:, :, pad:-pad, pad:-pad]\n",
    "            masks_list = [i.squeeze(0) for i in nozero_masks]\n",
    "            for i in zeros_idx:\n",
    "                masks_list.insert(i, torch.zeros((crop_size, crop_size)))\n",
    "            mask_row = torch.cat(masks_list, 0)\n",
    "        else:\n",
    "            mask_row = torch.zeros((crop_size, w))\n",
    "        rows.append(mask_row)\n",
    "    mask = np.uint8(torch.cat(rows, 0)[:h, :w]*255)\n",
    "    assert mask.shape == shape\n",
    "    return mask\n",
    "\n",
    "l = read_and_process_img(img_name, foo, 2048, 2000)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1, 2048, 2048])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7392a66b52e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_plot_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/PAMBuH/src/postprocessing.py\u001b[0m in \u001b[0;36m_plot_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "_plot_img(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31295, 40429)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61acce9c0089449b9d479f463288f042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rows:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97e6fa4118c4ce4ab2a372233c64818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "columns:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 1024, 1024] at entry 0 and [3, 1024, 1274] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-6e6cc5938e85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_process_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-145-b7b0d8aec80f>\u001b[0m in \u001b[0;36mread_and_process_img\u001b[0;34m(path, inf, size, crop_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mzeros_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzeros_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-04665b439297>\u001b[0m in \u001b[0;36m_infer_func\u001b[0;34m(imgs, cfg, model)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m#print(batch.shape, batch.dtype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 1024, 1024] at entry 0 and [3, 1024, 1274] at entry 2"
     ]
    }
   ],
   "source": [
    "mask = read_and_process_img(img_name, foo, size=2048, crop_size=2000)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 40429)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_plot_img(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_test_folder(foo, src_folder, './output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sampler.tif_block_read('./input/hm/test/b2dc8411c.tiff', block_size=(1024,1024))\n",
    "s = iter(s)\n",
    "_,_,img = next(s)\n",
    "print(img.shape, img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.transpose(1,2,0)).resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rio.open('./input/hm/train/095bf7a1f.tiff')\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 15750,16100\n",
    "w,h=1024,1024\n",
    "img = ds.read([1,2,3], window=((x,x+w),(y,y+h)))\n",
    "print(img.shape, img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.transpose(1,2,0)).resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = foo([img])\n",
    "bb.shape, bb.dtype, bb.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bb[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = callbacks.denorm(dxb[0], mean=cfg.TRANSFORMERS.MEAN, std=cfg.TRANSFORMERS.STD).squeeze()\n",
    "t = t.squeeze().permute(1,2,0).numpy()\n",
    "t.shape\n",
    "\n",
    "Image.fromarray((255.*t).astype(np.uint8))#.resize((512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
