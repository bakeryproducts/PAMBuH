{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('..')\n",
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as nn_model\n",
    "from model import conv_block, conv_once, downsample_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class seg_attention_block(nn.Module):\n",
    "    \"\"\"https://arxiv.org/pdf/1804.03999.pdf\"\"\"\n",
    "    def __init__(self, fg, fl, fint, name='att'):\n",
    "        super(seg_attention_block, self).__init__()\n",
    "        name1 = name +'_gate_'\n",
    "        self.wg = nn.Sequential(OrderedDict([\n",
    "                                (name1+'conv',nn.Conv2d(fg, fint, kernel_size=1,stride=1,padding=0,bias=False)),\n",
    "                                (name1+'norm',nn.BatchNorm2d(fint))\n",
    "        ]))\n",
    "                                \n",
    "        name2 = name +'_signal_'             \n",
    "        self.wx = nn.Sequential(OrderedDict([\n",
    "                                (name2+'conv',nn.Conv2d(fl, fint, kernel_size=1,stride=1,padding=0,bias=False)),\n",
    "                                (name2+'norm',nn.BatchNorm2d(fint))\n",
    "        ]))\n",
    "            \n",
    "        name3 = name +'_merge_'\n",
    "        self.psi = nn.Sequential(OrderedDict([\n",
    "                                (name3+'conv',nn.Conv2d(fint, 1, kernel_size=1,stride=1,padding=0,bias=False)),\n",
    "                                (name3+'norm',nn.BatchNorm2d(1)),\n",
    "                                (name3+'sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.wg(g)\n",
    "        x1 = self.wx(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x*psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _base_enc_unet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(_base_enc_unet, self).__init__()\n",
    "        self.init_features = init_features\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        f = init_features\n",
    "        self.e1 = conv_block(in_channels, f, 'e1')\n",
    "        self.downsample1 = downsample_block(f,f,'d1')\n",
    "        self.e2 = conv_block(f, 2*f, 'e2')\n",
    "        self.downsample2 = downsample_block(2*f,2*f,'d2')\n",
    "        self.e3 = conv_block(2*f, 4*f, 'e3')\n",
    "        self.downsample3 = downsample_block(4*f,4*f,'d3')\n",
    "        self.e4 = conv_block(4*f, 8*f, 'e4')\n",
    "        self.downsample4 = downsample_block(8*f,8*f,'d4')\n",
    "        self.bottleneck = conv_block(8*f, 16*f, 'bottleneck')\n",
    "        \n",
    "    def cat(self, a,b):\n",
    "        # cat with fixed shape\n",
    "        min_x = min(a.shape[-2], b.shape[-2])\n",
    "        min_y = min(a.shape[-1], b.shape[-1])\n",
    "        return torch.cat((a[...,:min_x, :min_y], b[...,:min_x, :min_y]), dim=1)\n",
    "        \n",
    "    def forward_encoding(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.downsample1(e1))\n",
    "        e3 = self.e3(self.downsample2(e2))\n",
    "        e4 = self.e4(self.downsample3(e3))\n",
    "        bottleneck = self.bottleneck(self.downsample4(e4))\n",
    "        return e1,e2,e3,e4,bottleneck\n",
    "\n",
    "    \n",
    "class _base_unet(_base_enc_unet):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(_base_unet, self).__init__( *args, **kwargs)\n",
    "        f = self.init_features\n",
    "        \n",
    "        self.upsample4 = nn.ConvTranspose2d(f*16, f*8, kernel_size=2, stride=2)\n",
    "        self.d4 =  conv_block(16*f, 8*f, 'd4')\n",
    "        self.upsample3 = nn.ConvTranspose2d(f*8, f*4, kernel_size=2, stride=2)\n",
    "        self.d3 =  conv_block(8*f, 4*f, 'd3')\n",
    "        self.upsample2 = nn.ConvTranspose2d(f*4, f*2, kernel_size=2, stride=2)\n",
    "        self.d2 =  conv_block(4*f, 2*f, 'd2')\n",
    "        self.upsample1 = nn.ConvTranspose2d(f*2, f, kernel_size=2, stride=2)\n",
    "        self.d1 =  conv_block(2*f, f, 'd1')\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1,e2,e3,e4,bottleneck = self.forward_encoding(x)\n",
    "        \n",
    "        # decoding + concat path\n",
    "        d4 = self.upsample4(bottleneck) \n",
    "        d4 = self.d4(self.cat(d4,e4))\n",
    "        \n",
    "        d3 = self.upsample3(d4)\n",
    "        d3 = self.d3(self.cat(d3,e3))\n",
    "        \n",
    "        d2 = self.upsample2(d3) \n",
    "        d2 = self.d2(self.cat(d2,e2))\n",
    "        \n",
    "        d1 = self.upsample1(d2)\n",
    "        d1 = self.d1(self.cat(d1,e1))\n",
    "        return d1\n",
    "\n",
    "class att_unet(_base_unet):\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(att_unet, self).__init__(in_channels, out_channels, init_features)\n",
    "        f = self.init_features\n",
    "        self.ag4 = seg_attention_block(f*8, f*8, f*4, 'att4')\n",
    "        self.ag3 = seg_attention_block(f*4, f*4, f*2, 'att3')\n",
    "        self.ag2 = seg_attention_block(f*2, f*2, f, 'att2')\n",
    "        self.ag1 = seg_attention_block(f, f, f, 'att1')\n",
    "        self.conv_1x1 = nn.Conv2d(f, self.out_channels, kernel_size=1,stride=1,padding=0)\n",
    "    \n",
    "    def _layer_init(self): nn.init.constant_(self.conv_1x1.bias, -4.59)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1,e2,e3,e4,bottleneck = self.forward_encoding(x)\n",
    "        \n",
    "        d4 = self.upsample4(bottleneck) \n",
    "        ea4 = self.ag4(d4, e4)\n",
    "        d4 = self.d4(self.cat(d4,ea4))\n",
    "        \n",
    "        d3 = self.upsample3(d4)\n",
    "        ea3 = self.ag3(d3, e3)\n",
    "        d3 = self.d3(self.cat(d3,ea3))\n",
    "        \n",
    "        d2 = self.upsample2(d3) \n",
    "        ea2 = self.ag2(d2, e2)\n",
    "        d2 = self.d2(self.cat(d2,ea2))\n",
    "        \n",
    "        d1 = self.upsample1(d2)\n",
    "        ea1 = self.ag1(d1, e1)\n",
    "        d1 = self.d1(self.cat(d1,ea1))\n",
    "        \n",
    "        return self.conv_1x1(d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import data\n",
    "from config import cfg, cfg_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_init('./src/configs/unet_gelb.yaml')\n",
    "cfg['PARALLEL']['DDP'] = False\n",
    "cfg['DATA'][\"TRAIN\"][\"PRELOAD\"]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = att_unet(3,1,32).cuda()#nn_model.Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = data.build_datasets(cfg)\n",
    "dls = data.build_dataloaders(cfg, datasets, pin=True, drop_last=False)\n",
    "dl = dls['TRAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb,yb in dl:\n",
    "    #preds = model(xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(xb.cuda())\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.manet.MAnet(encoder_name='se_resnet50', encoder_depth=5)\n",
    "#model = smp.UnetPlusPlus(encoder_name='se_resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(2,3,256,256).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.shape, p.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
